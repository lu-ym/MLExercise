{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Transformer Demo\n",
        "这个Demo主要是参考[《动手学深度学习》](https://github.com/d2l-ai/d2l-zh)中的[代码](https://github.com/d2l-ai/d2l-zh/blob/master/d2l/torch.py)，简单的梳理(体检)一下transfomer的大概框架和计算过程，尤其是中间shape的几次变换。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils import data\n",
        "from torchvision import transforms\n",
        "\n",
        "nn_Module = nn.Module\n",
        "\n",
        "import collections\n",
        "import hashlib\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import shutil\n",
        "import sys\n",
        "import tarfile\n",
        "import time\n",
        "import zipfile\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "import requests\n",
        "from IPython import display\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib_inline import backend_inline\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils import data\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "def sequence_mask(X, valid_len, value=0):\n",
        "    \"\"\"在序列中屏蔽不相关的项\n",
        "\n",
        "    Defined in :numref:`sec_seq2seq_decoder`\"\"\"\n",
        "    maxlen = X.size(1)\n",
        "    mask = torch.arange((maxlen), dtype=torch.float32,\n",
        "                        device=X.device)[None, :] < valid_len[:, None]\n",
        "    X[~mask] = value\n",
        "    return X\n",
        "\n",
        "def masked_softmax(X, valid_lens):\n",
        "    \"\"\"通过在最后一个轴上掩蔽元素来执行softmax操作\n",
        "\n",
        "    Defined in :numref:`sec_attention-scoring-functions`\"\"\"\n",
        "    # X:3D张量，valid_lens:1D或2D张量\n",
        "    if valid_lens is None:\n",
        "        return nn.functional.softmax(X, dim=-1)\n",
        "    else:\n",
        "        shape = X.shape\n",
        "        if valid_lens.dim() == 1:\n",
        "            valid_lens = torch.repeat_interleave(valid_lens, shape[1])\n",
        "        else:\n",
        "            valid_lens = valid_lens.reshape(-1)\n",
        "        # 最后一轴上被掩蔽的元素使用一个非常大的负值替换，从而其softmax输出为0\n",
        "        X = d2l.sequence_mask(X.reshape(-1, shape[-1]), valid_lens,\n",
        "                              value=-1e6)\n",
        "        return nn.functional.softmax(X.reshape(shape), dim=-1)\n",
        "\n",
        "class DotProductAttention(nn.Module):\n",
        "    \"\"\"缩放点积注意力\n",
        "\n",
        "    Defined in :numref:`subsec_additive-attention`\"\"\"\n",
        "    def __init__(self, dropout, **kwargs):\n",
        "        super(DotProductAttention, self).__init__(**kwargs)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    # queries的形状：(batch_size，查询的个数，d)\n",
        "    # keys的形状：(batch_size，“键－值”对的个数，d)\n",
        "    # values的形状：(batch_size，“键－值”对的个数，值的维度)\n",
        "    # valid_lens的形状:(batch_size，)或者(batch_size，查询的个数)\n",
        "    def forward(self, queries, keys, values, valid_lens=None):\n",
        "        d = queries.shape[-1]\n",
        "        # 设置transpose_b=True为了交换keys的最后两个维度\n",
        "        scores = torch.bmm(queries, keys.transpose(1,2)) / math.sqrt(d)\n",
        "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
        "        return torch.bmm(self.dropout(self.attention_weights), values)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7be21be0778d258b2a85d448d175280931934e7c4b8868294cf4ba82ea68406"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
